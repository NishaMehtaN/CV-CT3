{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6cc616-76c1-40dd-89db-10db32a2f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pywt\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QPushButton, QLabel, QFileDialog, QVBoxLayout, QHBoxLayout\n",
    "from PyQt5.QtGui import QPixmap, QImage\n",
    "from PyQt5.QtCore import Qt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53451b88-eeac-4deb-a977-0e9ee582e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess clean images\n",
    "def load_clean_image(image_path, size=(128, 128)):\n",
    "    \"\"\"Load an image and normalize it to [0, 1].\"\"\"\n",
    "    img = load_img(image_path, target_size=size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cfcba8b-e9d7-4c97-be95-6dff197292d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Gaussian noise\n",
    "def add_gaussian_noise(image_array, sigma=0.1):\n",
    "    \"\"\"Add Gaussian noise to an image.\"\"\"\n",
    "    noise = np.random.normal(0, sigma, image_array.shape)\n",
    "    noisy_image = np.clip(image_array + noise, 0, 1)\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23eb5120-a18a-4e48-b868-3679014da541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet-based denoising\n",
    "def wavelet_denoising(image, wavelet='db1', level=1):\n",
    "    \"\"\"Apply wavelet-based denoising to an RGB image by processing each channel separately.\"\"\"\n",
    "    # Initialize output image\n",
    "    denoised_image = np.zeros_like(image)\n",
    "    \n",
    "    # Process each channel (R, G, B) independently\n",
    "    for channel in range(image.shape[2]):\n",
    "        # Perform wavelet decomposition on the single channel\n",
    "        coeffs = pywt.wavedec2(image[:, :, channel], wavelet, level=level)\n",
    "        \n",
    "        # Estimate noise level and set threshold\n",
    "        detail_coeffs = coeffs[-1]\n",
    "        if isinstance(detail_coeffs, tuple):\n",
    "            all_details = np.concatenate([c.flatten() for c in detail_coeffs])\n",
    "        else:\n",
    "            all_details = detail_coeffs.flatten()\n",
    "        threshold = np.std(all_details) * np.sqrt(2 * np.log(image.size // image.shape[2]))\n",
    "        \n",
    "        # Threshold the detail coefficients while preserving structure\n",
    "        thresholded_coeffs = [coeffs[0]]\n",
    "        for detail in coeffs[1:]:\n",
    "            if isinstance(detail, tuple):\n",
    "                thresholded_detail = tuple(pywt.threshold(c, threshold, mode='soft') for c in detail)\n",
    "            else:\n",
    "                thresholded_detail = pywt.threshold(detail, mode='soft')\n",
    "            thresholded_coeffs.append(thresholded_detail)\n",
    "        \n",
    "        # Reconstruct the denoised channel\n",
    "        denoised_channel = pywt.waverec2(thresholded_coeffs, wavelet)\n",
    "        denoised_image[:, :, channel] = np.clip(denoised_channel, 0, 1)\n",
    "    \n",
    "    return denoised_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07be1a7-3830-4325-9a0b-e474547c6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train a simple convolutional autoencoder\n",
    "def build_autoencoder(input_shape=(128, 128, 3)):\n",
    "    \"\"\"Build a convolutional autoencoder for denoising.\"\"\"\n",
    "    input_img = Input(shape=input_shape)\n",
    "    # Encoder\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    # Decoder\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc95e5f8-e565-4cad-a30c-f8ee92dfd69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise image using the autoencoder\n",
    "def denoise_image(autoencoder, noisy_image):\n",
    "    \"\"\"Denoise an image using the trained autoencoder.\"\"\"\n",
    "    noisy_image = np.expand_dims(noisy_image, axis=0)\n",
    "    denoised_image = autoencoder.predict(noisy_image, verbose=0)[0]\n",
    "    return denoised_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f86bdfe5-ec1a-4726-af7f-0204580a4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy array to QImage for PyQt5 display\n",
    "def numpy_to_qimage(image):\n",
    "    \"\"\"Convert a numpy image array to QImage.\"\"\"\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    if len(image.shape) == 3:\n",
    "        height, width, channel = image.shape\n",
    "        return QImage(image.data, width, height, 3 * width, QImage.Format_RGB888).rgbSwapped()\n",
    "    else:\n",
    "        height, width = image.shape\n",
    "        return QImage(image.data, width, height, width, QImage.Format_Grayscale8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "034dc398-2529-49f6-84c9-4e1ddedba507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation metrics\n",
    "def compute_metrics(original, denoised):\n",
    "    \"\"\"Compute PSNR, SSIM, and MSE between original and denoised images.\"\"\"\n",
    "    mse = np.mean((original - denoised) ** 2)\n",
    "    psnr_value = psnr(original, denoised, data_range=1.0)\n",
    "    ssim_value = ssim(original, denoised, channel_axis=2, data_range=1.0)\n",
    "    return mse, psnr_value, ssim_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60226b6b-5a29-4ec8-a6c5-9974a3cde60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyQt5 Application\n",
    "class NoiseReductionApp(QWidget):\n",
    "    def __init__(self, autoencoder):\n",
    "        super().__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        \"\"\"Initialize the GUI layout.\"\"\"\n",
    "        self.setWindowTitle(\"Noise Reduction Comparison Tool\")\n",
    "        self.setGeometry(100, 100, 1200, 600)\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "        \n",
    "        # Upload button\n",
    "        self.upload_btn = QPushButton(\"Upload Image\", self)\n",
    "        self.upload_btn.clicked.connect(self.upload_image)\n",
    "        layout.addWidget(self.upload_btn)\n",
    "\n",
    "        # Labels for displaying images\n",
    "        self.image_labels = {\n",
    "            \"original\": QLabel(self),\n",
    "            \"noisy\": QLabel(self),\n",
    "            \"gaussian\": QLabel(self),\n",
    "            \"median\": QLabel(self),\n",
    "            \"wavelet\": QLabel(self),\n",
    "            \"autoencoder\": QLabel(self)\n",
    "        }\n",
    "        image_layout = QHBoxLayout()\n",
    "        for key, label in self.image_labels.items():\n",
    "            label.setAlignment(Qt.AlignCenter)\n",
    "            label_layout = QVBoxLayout()\n",
    "            label_layout.addWidget(QLabel(key.capitalize()))\n",
    "            label_layout.addWidget(label)\n",
    "            image_layout.addLayout(label_layout)\n",
    "        layout.addLayout(image_layout)\n",
    "\n",
    "        # Metrics display\n",
    "        self.metrics_label = QLabel(\"Metrics: Not computed\", self)\n",
    "        layout.addWidget(self.metrics_label)\n",
    "\n",
    "        self.setLayout(layout)\n",
    "\n",
    "    def upload_image(self):\n",
    "        \"\"\"Handle image upload and denoising.\"\"\"\n",
    "        file_path, _ = QFileDialog.getOpenFileName(self, \"Select Image\", \"\", \"Image Files (*.png *.jpg *.jpeg)\")\n",
    "        if file_path:\n",
    "            # Load and preprocess image\n",
    "            image = load_clean_image(file_path)\n",
    "            if image is None:\n",
    "                return\n",
    "            \n",
    "            noisy_image = add_gaussian_noise(image)\n",
    "\n",
    "            # Apply denoising techniques\n",
    "            gaussian_denoised = cv2.GaussianBlur(noisy_image, (5, 5), 0)\n",
    "            median_denoised = cv2.medianBlur((noisy_image * 255).astype(np.uint8), 5) / 255.0\n",
    "            wavelet_denoised = wavelet_denoising(noisy_image)\n",
    "            autoencoder_denoised = denoise_image(self.autoencoder, noisy_image)\n",
    "\n",
    "            # Display images\n",
    "            self.image_labels[\"original\"].setPixmap(QPixmap.fromImage(numpy_to_qimage(image)))\n",
    "            self.image_labels[\"noisy\"].setPixmap(QPixmap.fromImage(numpy_to_qimage(noisy_image)))\n",
    "            self.image_labels[\"gaussian\"].setPixmap(QPixmap.fromImage(numpy_to_qimage(gaussian_denoised)))\n",
    "            self.image_labels[\"median\"].setPixmap(QPixmap.fromImage(numpy_to_qimage(median_denoised)))\n",
    "            self.image_labels[\"wavelet\"].setPixmap(QPixmap.fromImage(numpy_to_qimage(wavelet_denoised)))\n",
    "            self.image_labels[\"autoencoder\"].setPixmap(QPixmap.fromImage(numpy_to_qimage(autoencoder_denoised)))\n",
    "\n",
    "            # Compute and display metrics\n",
    "            metrics = {\n",
    "                \"Gaussian\": compute_metrics(image, gaussian_denoised),\n",
    "                \"Median\": compute_metrics(image, median_denoised),\n",
    "                \"Wavelet\": compute_metrics(image, wavelet_denoised),\n",
    "                \"Autoencoder\": compute_metrics(image, autoencoder_denoised)\n",
    "            }\n",
    "            metrics_text = \"\\n\".join([f\"{key}: MSE={m[0]:.4f}, PSNR={m[1]:.2f}, SSIM={m[2]:.4f}\" for key, m in metrics.items()])\n",
    "            self.metrics_label.setText(f\"Metrics:\\n{metrics_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97a8b5eb-711e-42b9-832f-6d95ecf8f0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.1146 - val_loss: 0.1163\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.1090 - val_loss: 0.1094\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.1039 - val_loss: 0.1025\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0989 - val_loss: 0.0959\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0942 - val_loss: 0.0909\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0907 - val_loss: 0.0874\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0880 - val_loss: 0.0847\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0849 - val_loss: 0.0826\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0815 - val_loss: 0.0813\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0780 - val_loss: 0.0805\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset (example: use a small subset for training)\n",
    "dataset_path = \"C://Users/user/OneDrive/Documents/SRM-Classes/Sem4/20PCSC55J-ComputerVision/CT3Dataset\"  \n",
    "clean_images = []\n",
    "noisy_images = []\n",
    "if not os.path.exists(dataset_path):\n",
    "    logging.error(f\"Dataset path {dataset_path} does not exist\")\n",
    "    sys.exit(1)\n",
    "\n",
    "for filename in os.listdir(dataset_path)[:100]:  # Limit to 100 images for quick training\n",
    "    image_array = load_clean_image(os.path.join(dataset_path, filename))\n",
    "    if image_array is not None:\n",
    "        clean_images.append(image_array)\n",
    "        noisy_images.append(add_gaussian_noise(image_array))\n",
    "\n",
    "if not clean_images:\n",
    "    logging.error(\"No valid images loaded from dataset\")\n",
    "    sys.exit(1)\n",
    "\n",
    "clean_images = np.array(clean_images)\n",
    "noisy_images = np.array(noisy_images)\n",
    "\n",
    "# Build and train autoencoder\n",
    "autoencoder = build_autoencoder()\n",
    "if autoencoder is None:\n",
    "    logging.error(\"Failed to build autoencoder\")\n",
    "    sys.exit(1)\n",
    "\n",
    "autoencoder.fit(noisy_images, clean_images, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Run PyQt5 application\n",
    "app = QApplication(sys.argv)\n",
    "window = NoiseReductionApp(autoencoder)\n",
    "window.show()\n",
    "sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb53db-d902-4be3-b167-bf2c683b69d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
